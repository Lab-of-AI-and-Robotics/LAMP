<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <meta name="title" content="LAMP: Implicit Language Map for Robot Navigation - Sibaek Lee, Hyeonwoo Yu, Giseop Kim, Sunwook Choi">
  <meta name="description" content="LAMP introduces a novel approach to language-driven robot navigation using implicit neural fields for memory-efficient mapping and precise goal reaching in large-scale environments.">
  <meta name="keywords" content="robot navigation, implicit neural fields, language mapping, SLAM, natural language commands, robotics, neural fields, path planning, autonomous navigation">
  <meta name="author" content="Sibaek Lee, Hyeonwoo Yu, Giseop Kim, Sunwook Choi">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <meta property="og:site_name" content="Sungkyunkwan University">
  <meta property="og:title" content="LAMP: Implicit Language Map for Robot Navigation">
  <meta property="og:description" content="Novel approach to language-driven robot navigation using implicit neural fields for memory-efficient mapping in large-scale environments.")
  <!-- TODO: Replace with your actual website URL -->
  <meta property="og:url" content="https://lab-of-ai-and-robotics.github.io/LAMP/">
  <!-- TODO: Create a 1200x630px preview image and update path -->
  <meta property="og:image" content="/Users/minjaelee/Desktop/coding/LAMP/docs/static/images/figure_method.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="LAMP: Implicit Language Map for Robot Navigation">
  <meta property="article:published_time" content="2025-01-01T00:00:00.000Z">
  <meta property="article:author" content="Sibaek Lee">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="LAMP">
  <meta property="article:tag" content="Implicit Language Map for robot Navigation">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <!-- TODO: Replace with your lab/institution Twitter handle -->
  <meta name="twitter:site" content="@YOUR_TWITTER_HANDLE">
  <meta name="twitter:creator" content="@sibaeklee">
  <meta name="twitter:title" content="LAMP: Implicit Language Map for Robot Navigation">
  <meta name="twitter:description" content="Novel approach to language-driven robot navigation using implicit neural fields for memory-efficient mapping in large-scale environments.")
  <!-- TODO: Same as social preview image above -->
  <meta name="twitter:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta name="twitter:image:alt" content="PAPER_TITLE - Research Preview">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="LAMP: Implicit Language Map for Robot Navigation">
  <meta name="citation_author" content="Lee, Sibaek">
  <meta name="citation_author" content="Yu, Hyeonwoo">
  <meta name="citation_author" content="Kim, Giseop">
  <meta name="citation_author" content="Choi, Sunwook">
  <meta name="citation_publication_date" content="2025">
  <meta name="citation_conference_title" content="IEEE Robotics and Automation Letters">
  <meta name="citation_pdf_url" content="https://YOUR_DOMAIN.com/static/pdfs/paper.pdf">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <title>LAMP: Implicit Language Map for Robot Navigation - Sibaek Lee, Hyeonwoo Yu, Giseop Kim, Sunwook Choi | IEEE RA-L 2025</title>
  
  <!-- Favicon and App Icons -->
  <!-- <link rel="icon" type="image/x-icon" href="static/images/favicon.ico"> -->
  <!-- <link rel="apple-touch-icon" href="static/images/favicon.ico"> -->
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "LAMP: Implicit Language Map for Robot Navigation",
    "description": "LAMP introduces a novel approach to language-driven robot navigation using implicit neural fields for memory-efficient mapping and precise goal reaching in large-scale environments.",
    "author": [
      {
        "@type": "Person",
        "name": "Sibaek Lee",
        "affiliation": {
          "@type": "Organization",
          "name": "Sungkyunkwan University"
        }
      },
      {
        "@type": "Person",
        "name": "Hyeonwoo Yu",
        "affiliation": {
          "@type": "Organization",
          "name": "Sungkyunkwan University"
        }
      },
      {
        "@type": "Person",
        "name": "Giseop Kim",
        "affiliation": {
          "@type": "Organization",
          "name": "Sungkyunkwan University"
        }
      },
      {
        "@type": "Person",
        "name": "Sunwook Choi",
        "affiliation": {
          "@type": "Organization",
          "name": "Sungkyunkwan University"
        }
      }
    ],
    "datePublished": "2025-01-01",
    "publisher": {
      "@type": "Organization",
      "name": "IEEE Robotics and Automation Letters"
    },
    "url": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE",
    "image": "https://YOUR_DOMAIN.com/static/images/social_preview.png",
    "keywords": ["robot navigation", "implicit neural fields", "language mapping", "SLAM", "natural language commands", "robotics", "neural fields", "path planning", "autonomous navigation"],
    "abstract": "Enabling robots to follow natural language commands in large environments is challenging, as current mapping methods consume excessive memory. We introduce LAMP, a new navigation framework that uses an implicit neural field to learn a continuous, language-driven map of its surroundings. By combining a coarse search on a sparse graph with fine-grained, gradient-based optimization in the learned field, LAMP can precisely guide a robot to its goal.",
    "citation": "BIBTEX_CITATION_HERE",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "RESEARCH_AREA_1"
      },
      {
        "@type": "Thing", 
        "name": "RESEARCH_AREA_2"
      }
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "INSTITUTION_OR_LAB_NAME",
    "url": "https://YOUR_INSTITUTION_WEBSITE.com",
    "logo": "https://YOUR_DOMAIN.com/static/images/favicon.ico",
    "sameAs": [
      "https://twitter.com/YOUR_TWITTER_HANDLE",
      "https://github.com/YOUR_GITHUB_USERNAME"
    ]
  }
  </script>
</head>
<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  <!-- More Works Dropdown -->
  <!--
  <div class="more-works-container">
    <button class="more-works-btn" onclick="toggleMoreWorks()" title="View More Works from Our Lab">
      <i class="fas fa-flask"></i>
      More Works
      <i class="fas fa-chevron-down dropdown-arrow"></i>
    </button>
    <div class="more-works-dropdown" id="moreWorksDropdown">
      <div class="dropdown-header">
        <h4>More Works from Our Lab</h4>
        <button class="close-btn" onclick="toggleMoreWorks()">
          <i class="fas fa-times"></i>
        </button>
      </div>
      <div class="works-list">
        <a href="https://arxiv.org/abs/PAPER_ID_1" class="work-item" target="_blank">
          <div class="work-info">
            <h5>Paper Title 1</h5>
            <p>Brief description of the work and its main contribution.</p>
            <span class="work-venue">Conference/Journal 2024</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
        <a href="https://arxiv.org/abs/PAPER_ID_2" class="work-item" target="_blank">
          <div class="work-info">
            <h5>Paper Title 2</h5>
            <p>Brief description of the work and its main contribution.</p>
            <span class="work-venue">Conference/Journal 2023</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
        <a href="https://arxiv.org/abs/PAPER_ID_3" class="work-item" target="_blank">
          <div class="work-info">
            <h5>Paper Title 3</h5>
            <p>Brief description of the work and its main contribution.</p>
            <span class="work-venue">Conference/Journal 2023</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
      </div>
    </div>
  </div>
  -->

  <main id="main-content">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <!-- TODO: Replace with your paper title -->
            <h1 class="title is-1 publication-title">üí° LAMP: Implicit Language Map for Robot Navigation</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://sibaek-lee.github.io/" target="_blank">Sibaek Lee</a><sup>1,2,‚Ä†</sup>,</span>
              <span class="author-block">
                <a href="https://bogus2000.github.io/" target="_blank">Hyeonwoo Yu</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=9mKOLX8AAAAJ&hl=ko&oi=ao" target="_blank">Giseop Kim</a><sup>3</sup>,</span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=R3W7dTsAAAAJ&hl=ko" target="_blank">Sunwook Choi</a><sup>2,*</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Sungkyunkwan University</span>
              <span class="author-block"><sup>2</sup>NAVER LABS</span>
              <span class="author-block"><sup>3</sup>DGIST</span>
            </div>

            <div class="is-size-6 publication-authors">
              <span class="author-block">
                <small>
                  <sup>‚Ä†</sup>Work done during an internship at NAVER LABS<br>
                  <sup>*</sup>Corresponding author
                </small>
              </span>
            </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                      <span class="link-block">
                        <a href="https://ieeexplore.ieee.org/document/11197901"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <span class="link-block">
                      <a href="https://www.arxiv.org/abs/2602.11862"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="ai ai-arxiv"></i>
                      </span>
                      <span>ArXiv</span>
                    </a>
                  </span>

              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=SWdm7wHuiCo"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fab fa-youtube"></i>
                </span>
                <span>Video</span>
              </a>
            </span>

            <span class="link-block">
              <a href="static/pdfs/lamp.pdf"
              class="external-link button is-normal is-rounded is-dark">
              <span class="icon">
                <i class="fas fa-file-pdf"></i>
              </span>
              <span>Poster</span>
            </a>
          </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="lamp-video" autoplay controls muted loop height="100%" preload="metadata">
        <source src="static/videos/LAMP.mp4" type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        LAMP demonstrates large-scale language-driven robot navigation through implicit neural fields, achieving memory-efficient mapping and precise goal reaching.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <!-- TODO: Replace with your paper abstract -->
          <p>
            Enabling robots to follow natural language commands in large environments is challenging, as current mapping methods consume excessive memory. We introduce LAMP, a new navigation framework that uses an implicit neural field to learn a continuous, language-driven map of its surroundings. By combining a coarse search on a sparse graph with fine-grained, gradient-based optimization in the learned field, LAMP can precisely guide a robot to its goal. Our experiments show that this approach is significantly more memory-efficient and accurate than existing methods, opening new possibilities for scalable, language-aware robots.  
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Method Section -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method</h2>
        <div class="content has-text-justified">
          <p>
            LAMP introduces a novel approach to language-driven robot navigation by learning an implicit neural field that continuously encodes language features across large-scale environments. Our method consists of three key components that work together to enable memory-efficient and precise navigation.
          </p>
        </div>

        <!-- Method Figure -->
        <div class="publication-banner">
          <img src="static/images/figure_method.png" alt="LAMP Method Overview" class="center">
        </div>

        <div class="content has-text-justified">
          <h3 class="title is-4">System Overview</h3>
          <p>
            <strong>(a) Implicit Language Map Construction:</strong> The robot traverses the environment and collects pairs of camera poses x and corresponding images I. Our neural network F<sub>Œò</sub> maps each pose x to a language embedding z = F<sub>Œò</sub>(x). Since processing the full large-scale topological graph is computationally expensive, we sample the graph ùí¢ using our proposed score-based optimization for coarse planning.
          </p>

          <p>
            <strong>(b) Coarse Path Planning:</strong> Given a user's natural language query such as "red oak tree", we encode a goal embedding and apply A* search on the sampled graph ùí¢ to obtain a coarse path to the node whose embedding best matches the goal embedding.
          </p>

          <p>
            <strong>(c) Fine Path Generation:</strong> We then generate the precise pose using F<sub>Œò</sub> to maximize cosine similarity, moving from the coarse pose to a fine pose that offers a clear view of the target object through gradient-based optimization.
          </p>

          <h3 class="title is-4">Key Innovations</h3>
          <ul>
            <li><strong>Implicit Language Field:</strong> Unlike existing methods that explicitly store language vectors at every location, LAMP encodes language features as a continuous neural field, dramatically reducing memory requirements while maintaining fine-grained representation capability.</li>

            <li><strong>Bayesian Uncertainty Modeling:</strong> We adopt a von Mises-Fisher distribution to model embedding uncertainty, improving robustness when predicting language features for unobserved poses and reducing the impact of noisy CLIP embeddings.</li>

            <li><strong>Graph Sampling Strategy:</strong> Our method employs a novel node selection approach that combines view coverage, uncertainty scores, and semantic sensitivity to retain only the most informative nodes, enabling efficient large-scale navigation.</li>

            <li><strong>Two-Stage Path Planning:</strong> LAMP combines coarse graph-based planning with fine-grained gradient-based optimization in the learned field, achieving both global navigation capability and precise goal reaching.</li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Method Section -->


<!-- Image carousel -->
<!--
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <img src="static/images/carousel1.jpg" alt="First research result visualization" loading="lazy"/>
        <h2 class="subtitle has-text-centered">
        </h2>
      </div>
      <div class="item">
        <img src="static/images/carousel2.jpg" alt="Second research result visualization" loading="lazy"/>
        <h2 class="subtitle has-text-centered">
        </h2>
      </div>
      <div class="item">
        <img src="static/images/carousel3.jpg" alt="Third research result visualization" loading="lazy"/>
        <h2 class="subtitle has-text-centered">
       </h2>
     </div>
     <div class="item">
      <img src="static/images/carousel4.jpg" alt="Fourth research result visualization" loading="lazy"/>
      <h2 class="subtitle has-text-centered">
      </h2>
    </div>
  </div>
</div>
</div>
</section>
-->
<!-- End image carousel -->


<!-- Limitations Section -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Limitations</h2>
        <div class="content has-text-justified">
          <p>
            While LAMP demonstrates promising results in large-scale language-driven navigation, there are several limitations that should be considered:
          </p>
          <ul>
            <li><strong>CLIP vector dependency:</strong> Our method's performance is inherently tied to the quality and accuracy of CLIP embeddings. The navigation success varies significantly depending on the semantic clarity and distinctiveness of the target query. Objects with ambiguous visual features or similar appearance to other items may lead to incorrect node selection and suboptimal navigation outcomes.</li>
            <li><strong>Data-intensive training requirements:</strong> Since we implicitly model the pose-to-CLIP vector relationship through a neural network, our approach requires extensive training data to learn this complex mapping effectively. The implicit representation demands a large number of pose-image pairs to achieve robust performance, which may be challenging to collect in some environments.</li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Limitations Section -->


<!-- BibTex citation -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">

    <div class="bibtex-header">
      <h2 class="title">BibTeX</h2>
      <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
        <i class="fas fa-copy"></i>
        <span class="copy-text">Copy</span>
      </button>
    </div>
    <pre id="bibtex-code"><code>@article{lee2025lamp,
  title={{LAMP}: Implicit Language Map for Robot Navigation},
  author={Lee, Sibaek and Yu, Hyeonwoo and Kim, Giseop and Choi, Sunwook},
  journal={IEEE Robotics and Automation Letters},
  year={2025},
  publisher={IEEE}
}</code></pre>
  </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the¬†<a href="https://nerfies.github.io" target="_blank">Nerfies</a>¬†project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
